{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Programming\n",
    "\n",
    "- **dynamic programming** is both an optimization technique and a computer programming method.\n",
    "- it was introduced by **Richard Bellman** in **1953**.\n",
    "- the main idea is that **we can break down complicated problems into smaller subproblems** in a recursive manner. \n",
    "- then we find the solutions for these subproblem and finally we combine the sub results to find the final solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **dynamic programming** is a method for solving complex problem by breaking it down into a collection of simpler sub problems.\n",
    "- it is applicable to problems exhibiting the properties of overlapping sub problems. \n",
    "- dynamic programming takes far less time than other methods that don't take advantage of a subproblem overlap. \n",
    "- we need to solve different parts of the problem (sub problems) + combine the solutions of the sub problems to reach an overall solution. \n",
    "- we solve each sub problem only once - we reduce the number of computations. \n",
    "- sub problems can be stored in memory - **memoization** and **tabulation**\n",
    "\n",
    "#### Optimal Substructure \n",
    "- In computer science, a problem is said to have optimal substructure if an optimal solution can be constructed from optimal solutions of it's sub problems. \n",
    "\n",
    "#### Bellman-Equation \n",
    "- Of course there is a relationship between the sub results and the final result - this is what the **Bellman-equation** defines. \n",
    "\n",
    "NOTE: ,,If a given problem has optimal substructure and overlapping sub problems then we can use dynamic programming approach''\n",
    "\n",
    "<img src='./imgs/dynamic1.jpg' style='width:500px; height:300px;'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memoization and Tabulation \n",
    "- the problem of recursion is that we may solve the same problems multiple times. This can be eliminated by:\n",
    "\n",
    "- 1. Top-Down Approach ,,Memoization''\n",
    "    - We can store the solutions of the sub problems in a table (priority queue for example) \n",
    "\n",
    "    Whenever we try to solve a new sub problem we first check whether it is present in the table (so we have already solved that problem.)\n",
    "\n",
    "- 2. Bottom-Up Approach ,,Tabulation''\n",
    "    - We reformulate the original problem in a bottom-up fashion. We iteratively generate the sub results for larger and larger sub problems. \n",
    "\n",
    "#### Dynamic Programming and Divide and Conquer Approaches. \n",
    "- several problems can be solved by combining optimal solutions to non-overlapping sub problems. \n",
    "- this strategy is called divide and conquer method.\n",
    "- this is why merge sort (or quicksort) are not classified as dynamic programming problems. \n",
    "- overlapping sub problems - dynamic programming. \n",
    "- non-overlapping sub problems - divide and conquer method. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fibonacci Sequence using Dynamic Programming Approach\n",
    "\n",
    "<img src='./imgs/dynamic2.webp' style='width:500px; height:300px;'>\n",
    "\n",
    "\n",
    "#### Fibonacci Equation\n",
    "- F(N) = F(N-1) + F(N-2) \n",
    "\n",
    "#### Base Cases \n",
    "- F(0) = 0\n",
    "- F(1) = 1\n",
    "\n",
    "\n",
    "What is the problem with the recursive formula? We keep calculating same sub problems (Fibonacci numbers) over and over again?\n",
    "\n",
    "- let's use dynamic programming and memoization in order to avoid recalculating a subproblem over and over again.\n",
    "- we should use an associative array abstract data type to store the solution for the sub problems - **O(1)** time complexity. \n",
    "- on every **F()** method call - we insert the calculated value if necessary. \n",
    "- instead of the **O(2^N)** exponential time complexity we will have **O(N)** time complexity + requires **O(N)** space. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
